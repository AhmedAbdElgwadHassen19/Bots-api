const { GoogleGenerativeAI } = require('@google/generative-ai');
require('dotenv').config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

const chatCompletion = async (fullPrompt) => {
  try {
    console.log("ğŸ” Sending request to Gemini API with prompt:", fullPrompt);

    const model = genAI.getGenerativeModel({ model: "gemini-pro" });

    const result = await model.generateContent({
      contents: [{ parts: [{ text: fullPrompt }] }],
      generationConfig: {
        maxOutputTokens: 150, // âœ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù…Ù†Ø¹ Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§
        temperature: 0.7 // âœ… Ø¶Ø¨Ø· Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„Ù…Ù†Ø¹ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©
      }
    });

    if (!result.response || !result.response.candidates || result.response.candidates.length === 0) {
      throw new Error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯ Ù…Ù† Gemini.");
    }

    // âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ø±Ø¯ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·
    const text = result.response.candidates[0].content.parts[0].text.trim();

    console.log("âœ… Gemini Response:", text);
    return { status: 1, response: text };
  } catch (error) {
    console.error("âŒ Error calling Gemini:", error);
    return { status: 0, response: "âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Gemini." };
  }
};

module.exports = { chatCompletion };
